name: Scrape Eurofos CCCP13

on:
  schedule:
    - cron: "0 5 * * *"
    - cron: "0 8 * * *"
    - cron: "0 11 * * *"
    - cron: "0 13 * * *"
    - cron: "0 16 * * *"
    - cron: "0 19 * * *"
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
    - name: Cloner le repo
      uses: actions/checkout@v3
      with:
        persist-credentials: false

    - name: Installer Playwright + outils
      run: |
        pip install playwright
        playwright install chromium

    - name: Lancer le script de scraping
      run: python3 scrape_eurofos_playwright.py

    - name: Générer eurofos.json avec total et renfort
      run: |
        python3 <<EOF
import json
from collections import defaultdict

with open('eurofos.json') as f:
    data = json.load(f)

shifts = ['S1', 'S2', 'S3', 'JV']
parc = {shift: {'renfort': 0, 'total': 0} for shift in shifts}
latest_entries = {}

for entry in data:
    shift = entry['shift']
    zone = entry['zone']
    parc[shift]['total'] += 1
    key = (entry['date'], shift, zone)
    latest_entries[key] = entry

for (_, shift, _), _ in latest_entries.items():
    parc[shift]['renfort'] += 1

output = {
    'date': data[0]['date'] if data else '',
    'parc': parc
}

with open('eurofos.json', 'w') as f:
    json.dump(output, f, indent=2)
EOF

    - name: Commit du fichier structuré
      run: |
        git config user.name "github-actions"
        git config user.email "actions@github.com"
        git remote set-url origin https://x-access-token:${{ secrets.GH_PAT }}@github.com/${{ github.repository }}.git
        git add eurofos.json
        git commit -m "Mise à jour du fichier structuré eurofos.json" || echo "Aucun changement à commit"
        git push origin HEAD:main
